{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import TrainerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
    "\n",
    "# kogpt 모델 로드\n",
    "model_name = 'skt/kogpt2-base-v2' \n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name, bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "    pad_token='</s>')\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# data.txt(텍스트 데이터셋) 파일 로드\n",
    "with open(\"data.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = f.read()\n",
    "\n",
    "texts = [line.strip() for line in raw_data.split(\"\\n\") if line.strip()]\n",
    "\n",
    "\n",
    "train_size = int(0.85 * len(texts))\n",
    "train_texts = texts[:train_size]\n",
    "test_texts = texts[train_size:]\n",
    "\n",
    "train_dataset = Dataset.from_dict({'text': train_texts})\n",
    "test_dataset = Dataset.from_dict({'text': test_texts})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#토크나이징\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(examples[\"text\"], padding='max_length', max_length=512, truncation=True)\n",
    "    model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 파인튜닝1 \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=2,\n",
    "    evaluation_strategy=\"no\", \n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from google.colab import files\n",
    "from datasets import Dataset\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# qadata.txt(질의응답 json형태 데이터셋) 파일 로드\n",
    "with open(\"qadata.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_data = json.load(f)\n",
    "\n",
    "qa_dataset = Dataset.from_dict(qa_data)\n",
    "\n",
    "train_testsplit = qa_dataset.train_test_split(test_size=0.15)\n",
    "train_dataset = train_testsplit['train']\n",
    "test_dataset = train_testsplit['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#토크나이징\n",
    "def preprocess_function(examples):\n",
    "    inputs = [q + tokenizer.eos_token + a for q, a in zip(examples['question'], examples['answer'])]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#파인튜닝2\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    evaluation_strategy=\"epoch\", \n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,  \n",
    "    eval_dataset=tokenized_test_dataset,   \n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 테스트 예시\n",
    "test_questions = [\n",
    "        \"의무유급제도란 무엇인가요?\",\n",
    "        \"제적이란 무엇인가요?\",\n",
    "        \"유급학기의 계절수업 성적은 어떻게 되나요?\",\n",
    "        \"의무유급 학기의 성적은 어떻게 되나요?\",\n",
    "        \"수료/수여대상자가 의무유급대상이 될 경우 어떻게 되나요?\",\n",
    "        \"성적은 어떻게 평가되나요?\",\n",
    "        \"매 학기에 정기시험은 몇회 있나요?\",\n",
    "        \"A등급의 비율은 얼마로 제한되나요?\",\n",
    "        \"상대평가 대상에서 제외되는 대상은 누구인가요?\",\n",
    "        \"성적 확인이 제한되는 경우는 어떤 것이 있나요?\",\n",
    "        \"학사경고 사항은 어디에 기재되나요?\",\n",
    "        \"학사경고자는 어떤 조치가 따르나요?\",\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    inputs = tokenizer.encode(question + tokenizer.eos_token, return_tensors='pt').to(model.device)\n",
    "    outputs = model.generate(inputs, max_length=512, do_sample=True, top_k=50)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    answer = generated_text[len(question):].strip()\n",
    "    print(f\"질문: {question}\")\n",
    "    print(f\"답변: {answer}\")\n",
    "    print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# loss 값을 저장할 클래스\n",
    "class LossRecorder(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.train_epochs = []\n",
    "        self.eval_losses = []\n",
    "        self.eval_epochs = []\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            if 'loss' in logs:\n",
    "                self.train_losses.append(logs['loss'])\n",
    "                self.train_epochs.append(state.epoch)\n",
    "            if 'eval_loss' in logs:\n",
    "                self.eval_losses.append(logs['eval_loss'])\n",
    "                self.eval_epochs.append(state.epoch)\n",
    "\n",
    "loss_recorder = LossRecorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 추가학습\n",
    "training_args.num_train_epochs = 10\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    callbacks=[loss_recorder],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 손실 값 가져오기\n",
    "train_epochs = loss_recorder.train_epochs\n",
    "train_losses = loss_recorder.train_losses\n",
    "eval_epochs = loss_recorder.eval_epochs\n",
    "eval_losses = loss_recorder.eval_losses\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_epochs, train_losses, label='Training Loss')\n",
    "plt.plot(eval_epochs, eval_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 평가 (BLEU)\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# BLEU 계산 함수\n",
    "def calculate_bleu(references, hypotheses):\n",
    "    smooth = SmoothingFunction().method1  # Smoothing 함수 설정\n",
    "    bleu_scores = []\n",
    "    for ref, hyp in zip(references, hypotheses):\n",
    "        # BLEU-4 기준 점수 계산\n",
    "        score = sentence_bleu([ref.split()], hyp.split(), smoothing_function=smooth)\n",
    "        bleu_scores.append(score)\n",
    "    return bleu_scores\n",
    "\n",
    "# 모델 생성 답변 수집 함수\n",
    "def generate_answers(model, tokenizer, questions):\n",
    "    generated_answers = []\n",
    "    for question in questions:\n",
    "        inputs = tokenizer.encode(question + tokenizer.eos_token, return_tensors='pt').to(model.device)\n",
    "        outputs = model.generate(inputs, max_length=512, do_sample=True, top_k=50)\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        answer = generated_text[len(question):].strip()\n",
    "        generated_answers.append(answer)\n",
    "    return generated_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 테스트 질문\n",
    "test_questions = [\n",
    "    \"의무유급제도란 무엇인가요?\",\n",
    "    \"제적이란 무엇인가요?\",\n",
    "    \"유급학기의 계절수업 성적은 어떻게 되나요?\",\n",
    "    \"학기개시일 30일 이전에 일반휴학을 신청할 경우 얼마의 금액을 돌려받을 수 있나요?\",\n",
    "    \"학기개시일 30일에서 60일이 경과한 경우 얼마의 금액을 돌려받을 수 있나요?\",\n",
    "    \"창업휴학업무는 어디에서 담당하고 있나요?\",\n",
    "    \"복학 신청은 어디에서 가능한가요?\",\n",
    "    \"학석사 연계과정에는 어떤 것이 있나요?\"\n",
    "]\n",
    "\n",
    "# 생성된 답변 얻기\n",
    "generated_answers = generate_answers(model, tokenizer, test_questions)\n",
    "\n",
    "# 참조 답변 (정답)\n",
    "reference_answers = [\n",
    "    \"의무유급제도는 학업부진자에 대한 교육적 차원에서 학사경고 횟수에 따라 유급하도 록 하여 학생에게 학업 기회를 부여하는 제도입니다.\",\n",
    "    \"제적은 자퇴, 학사경고(의무유급 2회 후 재차 연속3회, 통산4회 받은 경우), 휴학기 간 종료 후 미복학, 미등록 등으로 인하여 학적을 상실하는 것입니다.\",\n",
    "    \"유급학기의 계절수업 및 해당학기 이후 휴학 중 계절수업을 통해 취득한 성적도 무효 처리됩니다.\",\n",
    "    \"학기 개시일 30일 경과 전일 경우 입학금을 제외한 등록금 전액이 반환됩니다.\",\n",
    "    \"학기 개시일 30일 경과한 날로부터 60일 경과 전일 경우 입학금을 제외한 등록금의 2/3에 해당하는 금액이 반환됩니다.\",\n",
    "    \"창업휴학업무는 창업지원단에서 담당하고 있습니다.\",\n",
    "    \"해당학기 학사일정에 정해진 휴·복학 기간 내 학사서비스(GLS)를 통해 복학 신청이 가능합니다.\",\n",
    "    \"학사과정 졸업유형에 따라 조기졸업트랙과 정규졸업트랙 두 가지가 있습니다.\"\n",
    "]\n",
    "\n",
    "# 출력 확인\n",
    "for i, (question, generated, reference) in enumerate(zip(test_questions, generated_answers, reference_answers)):\n",
    "    print(f\"질문 {i+1}: {question}\")\n",
    "    print(f\"모델 출력 답변: {generated}\")\n",
    "    print(f\"참조 답변: {reference}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# BLEU 점수 계산 (1에 가까울수록 좋음)\n",
    "bleu_scores = calculate_bleu(reference_answers, generated_answers)\n",
    "print(\"BLEU 점수:\")\n",
    "for i, score in enumerate(bleu_scores):\n",
    "    print(f\"질문 {i+1}의 BLEU 점수: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 베이스라인 모델 로드\n",
    "baseline_model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "for question in test_questions:\n",
    "    inputs = tokenizer.encode(question + tokenizer.eos_token, return_tensors='pt')\n",
    "    outputs = baseline_model.generate(inputs, max_length=50, do_sample=True, top_k=50)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    answer = generated_text[len(question):].strip()\n",
    "    print(f\"[베이스라인] 질문: {question}\")\n",
    "    print(f\"[베이스라인] 답변: {answer[len(question):]}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
